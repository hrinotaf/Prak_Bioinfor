{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrinotaf/Prak_Bioinfor/blob/main/Tgs_bioinfor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwAptX2sOW-x"
      },
      "source": [
        "**Praktikum Topik Bioinformatika\n",
        "Protein Secondary Structure Menggunakan Deep Neural Network**\n",
        "\n",
        "# Nama: Harin Noor Octafiani\n",
        "# NIM : G6501231035"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzTnrP_kV9Ya",
        "outputId": "30914ff8-4929-4e5d-9f22-7e266f4a1196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rBx5QZc9NtZI"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMs4FHZPED0",
        "outputId": "bad7481b-8440-4af4-ab4b-a76702cef069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.initializers import Initializer\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import files\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset_sec_protein.csv')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o69O9uDdPI_F"
      },
      "outputs": [],
      "source": [
        "#print(dataset)\n",
        "#Spliting data into training and testing\n",
        "X = dataset.iloc[:,1:261].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s4hGX5tcPYSm"
      },
      "outputs": [],
      "source": [
        "#print(dataset)\n",
        "#Spliting data into training and testing\n",
        "Y = dataset.iloc[:,261].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZuftAD5XPcmM"
      },
      "outputs": [],
      "source": [
        "#Label the class\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y1 = encoder.fit_transform(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1gdwoLXxPsWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847a3da1-b5d0-45fa-94d0-04f665c2d2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " ...\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "#print(y1)\n",
        "Y = pd.get_dummies(y1).values\n",
        "print(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HUgKWO2VPybq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "npJdVx45P4Tt"
      },
      "outputs": [],
      "source": [
        "#X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=60)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD,Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iNR0YUnERCi9"
      },
      "outputs": [],
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "      self.losses = []\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "     self.losses.append(logs.get('loss'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "2ZkBLnkZemwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Akx44kzROE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba4d476-d547-47f5-b948-4381e9088b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 8 \n"
          ]
        }
      ],
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 8\n",
        "print (\"Using batchsize = {} \".format (batch_size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDroyI5ZRTM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887ab169-a5c6-4da6-9fc3-a2fe05edb0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "125/125 [==============================] - 1s 2ms/step - loss: 0.9142 - accuracy: 0.6246\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7878\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8809\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9299\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9520\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9630\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9730\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9780\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9760\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9820\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9780\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9810\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9830\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9780\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9790\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9810\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9790\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9820\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9820\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9800\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9830\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9820\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.8899\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9159\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9640\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9770\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9760\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9790\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9760\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9790\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9810\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9770\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9780\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9790\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9790\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9820\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9820\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9780\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9830\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9820\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9840\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9840\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9820\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9820\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9800\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9810\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "125/125 [==============================] - 2s 3ms/step - loss: 0.8675 - accuracy: 0.6346\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8108\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8809\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2008 - accuracy: 0.9379\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9670\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9780\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9790\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9840\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9800\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9840\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9810\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9800\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9820\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9830\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9790\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9730\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9419\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9600\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9780\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9850\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9840\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9850\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9880\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9830\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9870\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9840\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9860\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9850\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9860\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9850\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9830\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9880\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9860\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9880\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9860\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9850\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9860\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9259\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9119\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9610\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9820\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9860\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9850\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9840\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9850\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9840\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9880\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9850\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9850\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9850\n",
            "63/63 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "125/125 [==============================] - 1s 2ms/step - loss: 0.9195 - accuracy: 0.6090\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8040\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8960\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9530\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9770\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9790\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9790\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9800\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9790\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9860\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9870\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9870\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9840\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9850\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9860\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9620\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1427 - accuracy: 0.9440\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9700\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9810\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9860\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9860\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9840\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9890\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9880\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9860\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9820\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9870\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9880\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9850\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9820\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9820\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9860\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9860\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9870\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9860\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9850\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9860\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9830\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9860\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9830\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9880\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9840\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9850\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9850\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9530\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8670\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9720\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9830\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9850\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Average Acc: 75.72% and StDev: (0.92%)\n",
            "Training Time 64.60187363624573\n"
          ]
        }
      ],
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=50,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "A_k7K71IWV6f"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 4\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yaAze8LWYAT",
        "outputId": "114d87c2-2a78-4945-ba8c-1234d49a7a77"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 4 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIKJeRoEWbuQ",
        "outputId": "6abd29f3-a385-4eb1-8082-45d89664c800"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 3ms/step - loss: 0.9284 - accuracy: 0.6246\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.8188\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.8959\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9359\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9530\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1410 - accuracy: 0.9550\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9720\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9690\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9660\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9580\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9520\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9750\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9770\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9780\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9800\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9830\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9820\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9800\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0258 - accuracy: 0.9840\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9790\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9810\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9820\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2569 - accuracy: 0.9209\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2565 - accuracy: 0.9059\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9530\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9740\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9820\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9800\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9820\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9800\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9800\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9820\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9780\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9830\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9800\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9850\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9870\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9800\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.9269\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.9389\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9710\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.9790\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9810\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9820\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9840\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9840\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9820\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9840\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9820\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9820\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9830\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9780\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9790\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.9219\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1052 - accuracy: 0.9630\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9740\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9780\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9820\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9820\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9840\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9810\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9820\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9830\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9840\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9850\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9840\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9820\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9750\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9830\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.9349\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1251 - accuracy: 0.9510\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9780\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9830\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9810\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9800\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9820\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9830\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9850\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0210 - accuracy: 0.9850\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9870\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0248 - accuracy: 0.9840\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.9840\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1255 - accuracy: 0.9600\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9590\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9730\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9760\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9810\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9830\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9850\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9790\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9830\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9850\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9840\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9850\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9850\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9840\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9830\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.9315 - accuracy: 0.6196\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.8158\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.8999\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9389\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9580\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9570\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9690\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9750\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0549 - accuracy: 0.9800\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9830\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9830\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9810\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9229\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9369\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0666 - accuracy: 0.9740\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9820\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9800\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9840\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9820\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9860\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9840\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9840\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9860\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9850\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9840\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8859\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1019 - accuracy: 0.9620\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9710\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9800\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9770\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9820\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9870\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9890\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9840\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9870\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9910\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9820\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9840\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9850\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9910\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9880\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2015 - accuracy: 0.9459\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.9109\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9760\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9810\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9870\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9850\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9860\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9860\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9860\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9860\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9870\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9760\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2336 - accuracy: 0.9229\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1185 - accuracy: 0.9640\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9800\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0411 - accuracy: 0.9810\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9850\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0258 - accuracy: 0.9860\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9840\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9880\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9880\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9850\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9890\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9840\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9880\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9870\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9870\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9840\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9870\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9880\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1633 - accuracy: 0.9640\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.9449\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0614 - accuracy: 0.9770\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9860\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9880\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9890\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9890\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9850\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9860\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9850\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9910\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9860\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.9279\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9770\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9790\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9750\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9850\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9880\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9860\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9850\n",
            "125/125 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.8691 - accuracy: 0.6580\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.8290\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9100\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9470\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9520\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9680\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9730\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9740\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9870\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9820\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9870\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9850\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9830\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9840\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1759 - accuracy: 0.9450\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.8840\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1143 - accuracy: 0.9600\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9750\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9770\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9820\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9850\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9850\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9870\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9870\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1192 - accuracy: 0.9580\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9540\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9790\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9820\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9860\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9860\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9840\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.9870\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9870\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9870\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9870\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9860\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9880\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9740\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3183 - accuracy: 0.9080\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9710\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9770\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9830\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9860\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9860\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9910\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9880\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9870\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9900\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9900\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9880\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0189 - accuracy: 0.9850\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9870\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9700\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2232 - accuracy: 0.9280\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9780\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9860\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9860\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9850\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9910\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9880\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9880\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9890\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9860\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9910\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9850\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.9220\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0772 - accuracy: 0.9670\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9820\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9850\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9840\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9900\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9870\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9880\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9860\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9910\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9900\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9890\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9910\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9630\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "Average Acc: 75.85% and StDev: (1.76%)\n",
            "Training Time 255.3596625328064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "Da9NVXZfdL7r"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 8\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz0UFF89exGO",
        "outputId": "4f031507-c343-4b90-d9ae-8e149ac3c971"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 8 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixtWXfbDe4Ai",
        "outputId": "7734fa7e-098b-4b33-a301-edacd87b2cee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 7ms/step - loss: 0.8956 - accuracy: 0.6587\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8288\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2856 - accuracy: 0.9019\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1874 - accuracy: 0.9399\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9710\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9740\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0843 - accuracy: 0.9780\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9760\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9710\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9770\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9700\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9520\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9680\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9680\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9630\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9700\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9810\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9780\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9830\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9820\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9810\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9840\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9790\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9820\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9750\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9800\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9780\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9790\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9780\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9790\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9800\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9810\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9840\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9820\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9800\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9800\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9810\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9489\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3795 - accuracy: 0.8659\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1272 - accuracy: 0.9439\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9650\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9770\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9800\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9680\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9820\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9840\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9810\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9830\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9790\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9850\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9830\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9840\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9820\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9800\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9810\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9810\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9800\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9760\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9820\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9860\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9800\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9820\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9820\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9840\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9810\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9830\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9840\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9399\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9099\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9670\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9690\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9780\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9820\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0235 - accuracy: 0.9820\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9810\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9820\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9860\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9860\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9850\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9810\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9830\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9840\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9810\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9830\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9830\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9790\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9850\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9850\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9860\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9830\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9850\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9830\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9880\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9650\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.9099\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9640\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9790\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9750\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9830\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9840\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.9098 - accuracy: 0.6356\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8428\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.9169\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 0.9469\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9720\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9760\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9790\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9860\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9850\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9830\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9830\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9850\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9880\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9850\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9870\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9880\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9860\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9069\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.8989\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9570\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.0608 - accuracy: 0.9780\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0303 - accuracy: 0.9850\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9840\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9860\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9870\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9860\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9820\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9850\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9850\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9860\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9830\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9870\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9880\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9870\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9880\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9860\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9840\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9840\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9850\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9830\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8679\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9449\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9770\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9860\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9870\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9850\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9890\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9900\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0176 - accuracy: 0.9850\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9870\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9910\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9900\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9880\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9830\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9880\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9910\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9900\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9510\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9159\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9700\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9870\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9880\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9860\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9860\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9860\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9840\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.8965 - accuracy: 0.6420\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8500\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9230\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9620\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9790\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9840\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9820\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9840\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9860\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9870\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9820\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9880\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9860\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9830\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9890\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9840\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0196 - accuracy: 0.9840\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9840\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9880\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9820\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9870\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9860\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9840\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9810\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.8240\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9130\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9720\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9760\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9870\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9870\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9890\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9880\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9840\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9870\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9850\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9830\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9860\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9900\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9890\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9860\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9860\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9870\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9890\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9870\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9850\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0290 - accuracy: 0.9860\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9880\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0213 - accuracy: 0.9860\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9860\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9880\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9110\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9460\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9720\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9820\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9870\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9870\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9890\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9850\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9890\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9870\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9890\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9860\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9880\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9860\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9860\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9880\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9890\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9890\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9850\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9890\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9900\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0149 - accuracy: 0.9890\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9900\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9880\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0191 - accuracy: 0.9850\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9860\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9360\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9390\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9770\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9790\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9830\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9840\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9780\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9870\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9880\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9880\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9860\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9900\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Average Acc: 76.25% and StDev: (1.98%)\n",
            "Training Time 256.5910608768463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "KgRngaFmiKft"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 8\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6El8lfVdiVda",
        "outputId": "c1c67a95-2de7-4134-a80d-e14e459bc351"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 8 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEAb1HxIiZ5T",
        "outputId": "35b6c32b-3845-4484-8b7b-b63d0b6c9ae3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 2ms/step - loss: 0.8499 - accuracy: 0.6416\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8258\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9179\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9530\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9660\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9750\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9780\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9810\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9780\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9760\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9790\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9770\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9770\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9830\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9800\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9770\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9790\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9790\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8939\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9530\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9780\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9810\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9790\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9800\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9790\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9820\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9840\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9790\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9780\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9780\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9790\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9820\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9780\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9760\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9800\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9790\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9790\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9800\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9790\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9800\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9790\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9830\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9820\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9810\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9810\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9690\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8949\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.1583 - accuracy: 0.9379\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9670\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9800\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9790\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9820\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9820\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9820\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9770\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 0.9800\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9820\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9810\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9780\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9770\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9790\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9800\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9800\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9810\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9800\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9830\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9830\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9760\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9810\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9820\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9800\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9800\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9810\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9830\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9810\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9820\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9229\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9499\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9690\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9760\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9830\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9800\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9850\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9810\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9810\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9820\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9810\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9820\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9840\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9840\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9830\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9810\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9840\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9830\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9840\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9840\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9820\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_52 (Dense)            (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 2ms/step - loss: 0.9240 - accuracy: 0.6306\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7998\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8779\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9209\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9540\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9740\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9790\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9850\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9830\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9840\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9860\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9830\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9850\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9840\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9850\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9860\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9850\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9670\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2186 - accuracy: 0.9329\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9469\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0566 - accuracy: 0.9780\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9840\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9840\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9870\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9860\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9860\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9870\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9850\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9860\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9860\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9860\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9840\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9870\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9870\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9850\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9880\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9870\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9860\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9850\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9850\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9830\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9850\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9870\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9870\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9249\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.9039\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9730\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9790\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9850\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9850\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9850\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9850\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9870\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9880\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9870\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9840\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9850\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9880\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9880\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9850\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9870\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9840\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9880\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9840\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9850\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9830\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9860\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9840\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9860\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9840\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9860\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9840\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9870\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9870\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9890\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9860\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9820\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9850\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9860\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9860\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9439\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.9079\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9720\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9860\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9880\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9870\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9870\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9890\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9870\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 0.9870\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9870\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9850\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 128)               33408     \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43843 (171.26 KB)\n",
            "Trainable params: 43843 (171.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.8611 - accuracy: 0.6460\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8190\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8920\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9530\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9790\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9840\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9840\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9780\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9860\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9860\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9840\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9860\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9870\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9860\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9860\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9870\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9840\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9160\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9510\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9740\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9790\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9830\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9850\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9850\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9890\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9870\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9840\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9850\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9860\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9860\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9870\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9870\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9830\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9880\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9850\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9850\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9870\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9870\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9870\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9830\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9850\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9850\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9860\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8450\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9470\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9810\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9860\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9860\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9860\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9890\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 0.9860\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9860\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9840\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9850\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9860\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9890\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9880\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9870\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9850\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9890\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9850\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9900\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9890\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9850\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9850\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9800\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8930\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9740\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9880\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9860\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9870\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9900\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9900\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9900\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9900\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9880\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9860\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9850\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Average Acc: 75.45% and StDev: (2.15%)\n",
            "Training Time 131.44807410240173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "jS_AipvRnt26"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 12\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMlxHUUpLnk",
        "outputId": "3e6b4b23-c18e-4d87-d056-9dc9a83df3d1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 12 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzPRreiepOvo",
        "outputId": "6415ae1f-a114-4c30-df81-2ffeae79bc64"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.9199 - accuracy: 0.6206\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8549\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9159\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9620\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9630\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1295 - accuracy: 0.9640\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9770\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9820\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9760\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9810\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9810\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9810\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9790\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9840\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9680\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9439\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9580\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9650\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9550\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9750\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9810\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9790\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9820\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9780\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9790\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9820\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9790\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9830\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9790\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9820\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9790\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9780\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9790\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9840\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9800\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9790\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9790\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9820\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9830\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9790\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9780\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9810\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9780\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9790\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9810\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9820\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9840\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9820\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9810\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9820\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9770\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9800\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9800\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 0.9840\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9319\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8709\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9399\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0756 - accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9790\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9750\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9820\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9800\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9820\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9790\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9800\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9810\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9810\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9810\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9790\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9800\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9820\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9790\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9820\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9790\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0211 - accuracy: 0.9820\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.9850\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9840\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9770\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9830\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9820\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9790\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9780\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9830\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9830\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9830\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9830\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9840\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9820\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9800\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9820\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9820\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9810\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9650\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9369\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9540\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9800\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9810\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9810\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9850\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9830\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_76 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.8488 - accuracy: 0.6326\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8268\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9249\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9620\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9770\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9840\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9870\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9820\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9840\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9830\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9870\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9860\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9860\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 0.9830\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9890\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9850\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9850\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9830\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9850\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9710\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8498\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9379\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9650\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9800\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9870\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9850\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9840\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9890\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9870\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9850\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9830\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9880\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9840\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9840\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9870\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9880\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9880\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9850\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9840\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9870\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9870\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9850\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9850\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9870\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9870\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9600\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9029\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9409\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9860\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9880\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9890\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9890\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9850\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9870\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9850\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9890\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9860\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9830\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9840\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9870\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9920\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9890\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9850\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9870\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9850\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9910\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9900\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9850\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9870\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 2s 5ms/step - loss: 0.9144 - accuracy: 0.6250\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8640\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9370\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.9710\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1051 - accuracy: 0.9700\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9830\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9830\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9830\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9870\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9860\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9850\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9870\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9830\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9840\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 0.9870\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9850\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9880\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9850\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9850\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9840\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9880\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9880\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9880\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9840\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9860\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9850\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9870\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9850\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9880\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9850\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9550\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8530\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9540\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9790\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9850\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9840\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9850\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9850\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9880\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9860\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9840\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9870\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9860\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9880\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9870\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9890\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9840\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9870\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 1s 9ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.0165 - accuracy: 0.9880\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9860\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9830\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9840\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9880\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9850\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9870\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9870\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9850\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9870\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9820\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9860\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9860\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9880\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9880\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9850\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9860\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9850\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9810\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8980\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9270\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9780\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9820\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9860\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9850\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9860\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9900\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9890\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9880\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9870\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9880\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9850\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9880\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9860\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9890\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "Average Acc: 76.25% and StDev: (1.72%)\n",
            "Training Time 109.50757122039795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "-1srZYQArWVB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 12\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZh_9CbxraPL",
        "outputId": "a824e6d4-bd90-4ad7-8fd3-3a08246c7c1f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 12 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=50,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se0zl9f2ra70",
        "outputId": "82f8e721-aeba-450b-f084-2f27c9c213f3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_84 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.9101 - accuracy: 0.6306\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8238\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.9109\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9630\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9710\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.9760\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9800\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9800\n",
            "Epoch 11/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9770\n",
            "Epoch 12/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9790\n",
            "Epoch 13/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9790\n",
            "Epoch 14/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9810\n",
            "Epoch 15/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9820\n",
            "Epoch 16/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9830\n",
            "Epoch 17/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9810\n",
            "Epoch 18/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9800\n",
            "Epoch 19/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9790\n",
            "Epoch 20/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9760\n",
            "Epoch 21/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9810\n",
            "Epoch 22/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9800\n",
            "Epoch 23/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9760\n",
            "Epoch 24/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9820\n",
            "Epoch 25/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9780\n",
            "Epoch 26/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9790\n",
            "Epoch 27/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9810\n",
            "Epoch 28/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9770\n",
            "Epoch 29/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9800\n",
            "Epoch 30/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 0.9780\n",
            "Epoch 31/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9770\n",
            "Epoch 32/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9810\n",
            "Epoch 33/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9790\n",
            "Epoch 34/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9790\n",
            "Epoch 35/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9820\n",
            "Epoch 36/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9540\n",
            "Epoch 37/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8158\n",
            "Epoch 38/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9299\n",
            "Epoch 39/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9660\n",
            "Epoch 40/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9760\n",
            "Epoch 41/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9810\n",
            "Epoch 42/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9820\n",
            "Epoch 43/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9820\n",
            "Epoch 44/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9780\n",
            "Epoch 45/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9800\n",
            "Epoch 46/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9810\n",
            "Epoch 47/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9810\n",
            "Epoch 48/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9800\n",
            "Epoch 49/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9780\n",
            "Epoch 50/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9830\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_88 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "84/84 [==============================] - 2s 3ms/step - loss: 0.8971 - accuracy: 0.6306\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8178\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9099\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9540\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9760\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9790\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9840\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9840\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9820\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9830\n",
            "Epoch 11/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9850\n",
            "Epoch 12/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9850\n",
            "Epoch 13/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9850\n",
            "Epoch 14/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9850\n",
            "Epoch 15/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9850\n",
            "Epoch 16/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9860\n",
            "Epoch 17/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9840\n",
            "Epoch 18/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9870\n",
            "Epoch 19/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9850\n",
            "Epoch 20/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9860\n",
            "Epoch 21/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9860\n",
            "Epoch 22/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9860\n",
            "Epoch 23/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9870\n",
            "Epoch 24/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9850\n",
            "Epoch 25/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9860\n",
            "Epoch 26/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9820\n",
            "Epoch 27/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9830\n",
            "Epoch 28/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9870\n",
            "Epoch 29/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9870\n",
            "Epoch 30/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9870\n",
            "Epoch 31/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9870\n",
            "Epoch 32/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9870\n",
            "Epoch 33/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9840\n",
            "Epoch 34/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.8148\n",
            "Epoch 35/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9249\n",
            "Epoch 36/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9660\n",
            "Epoch 37/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9800\n",
            "Epoch 38/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9860\n",
            "Epoch 39/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9870\n",
            "Epoch 40/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9880\n",
            "Epoch 41/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9880\n",
            "Epoch 42/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9870\n",
            "Epoch 43/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 44/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9880\n",
            "Epoch 45/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9880\n",
            "Epoch 46/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 47/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9860\n",
            "Epoch 48/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "Epoch 49/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9850\n",
            "Epoch 50/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "42/42 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_92 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "84/84 [==============================] - 2s 3ms/step - loss: 0.8739 - accuracy: 0.6580\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8690\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9440\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9670\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9840\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9820\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9820\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9860\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9870\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9860\n",
            "Epoch 11/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9840\n",
            "Epoch 12/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9870\n",
            "Epoch 13/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9880\n",
            "Epoch 14/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9860\n",
            "Epoch 15/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9860\n",
            "Epoch 16/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9850\n",
            "Epoch 17/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9870\n",
            "Epoch 18/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9840\n",
            "Epoch 19/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9880\n",
            "Epoch 20/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9840\n",
            "Epoch 21/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9870\n",
            "Epoch 22/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9880\n",
            "Epoch 23/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9830\n",
            "Epoch 24/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9860\n",
            "Epoch 25/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9850\n",
            "Epoch 26/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9870\n",
            "Epoch 27/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9820\n",
            "Epoch 28/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9860\n",
            "Epoch 29/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9290\n",
            "Epoch 30/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8780\n",
            "Epoch 31/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9550\n",
            "Epoch 32/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9810\n",
            "Epoch 33/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9860\n",
            "Epoch 34/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9840\n",
            "Epoch 35/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9860\n",
            "Epoch 36/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9820\n",
            "Epoch 37/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9870\n",
            "Epoch 38/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9900\n",
            "Epoch 39/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9890\n",
            "Epoch 40/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9870\n",
            "Epoch 41/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9840\n",
            "Epoch 42/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9870\n",
            "Epoch 43/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9860\n",
            "Epoch 44/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9840\n",
            "Epoch 45/50\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 46/50\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9870\n",
            "Epoch 47/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 48/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9840\n",
            "Epoch 49/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9840\n",
            "Epoch 50/50\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9870\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "Average Acc: 77.05% and StDev: (1.91%)\n",
            "Training Time 74.16307377815247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "pUJXPlsOr5__"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 12\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpp089VWr9bu",
        "outputId": "4eb7d996-9fd2-42bb-ae90-eed0dae46287"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 12 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=25,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVI6lnIsA0o",
        "outputId": "46fb75fa-0ff0-4ce1-e98f-322510650922"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 2s 7ms/step - loss: 0.8904 - accuracy: 0.6266\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8288\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8979\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9249\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9690\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9760\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9780\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9790\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9780\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9820\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9790\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9810\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9820\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9760\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9780\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9810\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9760\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9790\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9730\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9189\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9630\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9600\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9690\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9810\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9780\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_100 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 5ms/step - loss: 0.8693 - accuracy: 0.6416\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8488\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.2320 - accuracy: 0.9209\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9640\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9810\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9820\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9860\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9790\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0446 - accuracy: 0.9850\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9850\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9850\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9840\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9820\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9810\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9830\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9870\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9870\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9890\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9820\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9570\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8969\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9429\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9830\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9860\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9860\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_104 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.9748 - accuracy: 0.6220\n",
            "Epoch 2/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8350\n",
            "Epoch 3/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9290\n",
            "Epoch 4/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9700\n",
            "Epoch 5/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9760\n",
            "Epoch 6/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.9810\n",
            "Epoch 7/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9860\n",
            "Epoch 8/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9840\n",
            "Epoch 9/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9870\n",
            "Epoch 10/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9840\n",
            "Epoch 11/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9840\n",
            "Epoch 12/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9850\n",
            "Epoch 13/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9830\n",
            "Epoch 14/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9770\n",
            "Epoch 15/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9840\n",
            "Epoch 16/25\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9710\n",
            "Epoch 17/25\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9600\n",
            "Epoch 18/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 0.9720\n",
            "Epoch 19/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9660\n",
            "Epoch 20/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9810\n",
            "Epoch 21/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9860\n",
            "Epoch 22/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9840\n",
            "Epoch 23/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9880\n",
            "Epoch 24/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9850\n",
            "Epoch 25/25\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9860\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "Average Acc: 76.45% and StDev: (0.61%)\n",
            "Training Time 32.64916968345642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "YOeknM-7sc_L"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 8\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhI_oQosg1M",
        "outputId": "b5ece484-315b-4159-e77f-27a885d380b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 8 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=25,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFOYTYy5smX6",
        "outputId": "55381b45-04dd-4529-8c9a-9a097f890052"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_108 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.9091 - accuracy: 0.6496\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.8258\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.9079\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9570\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9620\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9750\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9750\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9790\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9750\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9820\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9800\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9800\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9790\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9790\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0375 - accuracy: 0.9800\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9790\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0497 - accuracy: 0.9770\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.8919\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1721 - accuracy: 0.9339\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9600\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9750\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9780\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9790\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9780\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9780\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_112 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.9020 - accuracy: 0.6396\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8408\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9269\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9580\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9610\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9750\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9790\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9840\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9800\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9850\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9820\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9850\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9840\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9830\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9830\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9850\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9840\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9860\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9850\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9890\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.9019\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9139\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9690\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9820\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9850\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_116 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "125/125 [==============================] - 2s 5ms/step - loss: 0.8444 - accuracy: 0.6620\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3879 - accuracy: 0.8560\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2152 - accuracy: 0.9180\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1490 - accuracy: 0.9570\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9820\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9840\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9860\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9830\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9860\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9820\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9880\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9880\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9850\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9830\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9880\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9850\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9850\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9880\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9850\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9870\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9860\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9870\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9890\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9890\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8270\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Average Acc: 76.05% and StDev: (2.80%)\n",
            "Training Time 47.40117835998535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "e559mqzhywSB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 12\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMdJ2n-rziGg",
        "outputId": "d6b1d849-9fcf-4f27-c262-4c5d7fe076db"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 12 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAbERHRqzoE3",
        "outputId": "a9a73fa7-cd5c-4e81-e775-cf4fcad52dee"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.8917 - accuracy: 0.6266\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8318\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9199\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9580\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9740\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9810\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9750\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9820\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9790\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9820\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9780\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9790\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9800\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9800\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9810\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9820\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9810\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9810\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9810\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9800\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 0.9790\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9800\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9790\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9790\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9790\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9810\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9790\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9810\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9810\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9880\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 0.9810\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.8448\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8969\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.9530\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9650\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9790\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9810\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9770\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9800\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9790\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9830\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9810\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9830\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9780\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9820\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9830\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9790\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9810\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9760\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9830\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9790\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9830\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9820\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 0.9810\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9840\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9830\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9840\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9800\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9800\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9830\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9790\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9840\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9800\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9810\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9800\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9840\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9840\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9790\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9800\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9780\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9840\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9800\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9780\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9800\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9790\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8939\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.9049\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9690\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9820\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9810\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9830\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9830\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9810\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9800\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9800\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9800\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9820\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9850\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9810\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9820\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9790\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9840\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9860\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9850\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9820\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9800\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_136 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.9272 - accuracy: 0.6386\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8458\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9209\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9640\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9710\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9770\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9850\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9840\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9850\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9840\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9830\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9800\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9830\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9810\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9770\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9680\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9469\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9550\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9840\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9870\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9850\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9890\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9850\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9860\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9860\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9850\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9870\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9840\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9870\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9860\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9860\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9850\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 0.9840\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9880\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9860\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9840\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9860\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9900\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9870\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9870\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9870\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9860\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9870\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9860\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9850\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9820\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9850\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9880\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9870\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9860\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9419\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8689\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9510\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9760\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9830\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9820\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9870\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9870\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9860\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9860\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9870\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9870\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9830\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9850\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9860\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9870\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9880\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9860\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9870\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9890\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9840\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9900\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9900\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9850\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9860\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9890\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9880\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9870\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9890\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9840\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9890\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9890\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9870\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9840\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9850\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9890\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9850\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_140 (Dense)           (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.8405 - accuracy: 0.6350\n",
            "Epoch 2/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8620\n",
            "Epoch 3/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9410\n",
            "Epoch 4/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9660\n",
            "Epoch 5/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9820\n",
            "Epoch 6/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9850\n",
            "Epoch 7/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9770\n",
            "Epoch 8/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9840\n",
            "Epoch 9/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9860\n",
            "Epoch 10/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9850\n",
            "Epoch 11/100\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9860\n",
            "Epoch 12/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9860\n",
            "Epoch 13/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9850\n",
            "Epoch 14/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9850\n",
            "Epoch 15/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9850\n",
            "Epoch 16/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9860\n",
            "Epoch 17/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9840\n",
            "Epoch 18/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9830\n",
            "Epoch 19/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9830\n",
            "Epoch 20/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9850\n",
            "Epoch 21/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 0.9860\n",
            "Epoch 22/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9880\n",
            "Epoch 23/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9830\n",
            "Epoch 24/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9850\n",
            "Epoch 25/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9820\n",
            "Epoch 26/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9860\n",
            "Epoch 27/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9830\n",
            "Epoch 28/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9850\n",
            "Epoch 29/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 0.9860\n",
            "Epoch 30/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9860\n",
            "Epoch 31/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9850\n",
            "Epoch 32/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9850\n",
            "Epoch 33/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9860\n",
            "Epoch 34/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9880\n",
            "Epoch 35/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9840\n",
            "Epoch 36/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9860\n",
            "Epoch 37/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 38/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9850\n",
            "Epoch 39/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9860\n",
            "Epoch 40/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9870\n",
            "Epoch 41/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8000\n",
            "Epoch 42/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9160\n",
            "Epoch 43/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9520\n",
            "Epoch 44/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9690\n",
            "Epoch 45/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9870\n",
            "Epoch 46/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9840\n",
            "Epoch 47/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9840\n",
            "Epoch 48/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9860\n",
            "Epoch 49/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9830\n",
            "Epoch 50/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9880\n",
            "Epoch 51/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9840\n",
            "Epoch 52/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9860\n",
            "Epoch 53/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9890\n",
            "Epoch 54/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9840\n",
            "Epoch 55/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9830\n",
            "Epoch 56/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9840\n",
            "Epoch 57/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9870\n",
            "Epoch 58/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9840\n",
            "Epoch 59/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9860\n",
            "Epoch 60/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9880\n",
            "Epoch 61/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9850\n",
            "Epoch 62/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 63/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 64/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9850\n",
            "Epoch 65/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 66/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9870\n",
            "Epoch 67/100\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9860\n",
            "Epoch 68/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9830\n",
            "Epoch 69/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9850\n",
            "Epoch 70/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9840\n",
            "Epoch 71/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 72/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 73/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 0.9860\n",
            "Epoch 74/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 75/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9860\n",
            "Epoch 76/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9180\n",
            "Epoch 77/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9320\n",
            "Epoch 78/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9790\n",
            "Epoch 79/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9850\n",
            "Epoch 80/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9880\n",
            "Epoch 81/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9880\n",
            "Epoch 82/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9850\n",
            "Epoch 83/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9860\n",
            "Epoch 84/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9890\n",
            "Epoch 85/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9830\n",
            "Epoch 86/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9850\n",
            "Epoch 87/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 88/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 89/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 90/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 91/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9880\n",
            "Epoch 92/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 93/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 94/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 95/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9860\n",
            "Epoch 96/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 97/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9870\n",
            "Epoch 98/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 99/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9850\n",
            "Epoch 100/100\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9850\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "Average Acc: 77.45% and StDev: (0.81%)\n",
            "Training Time 122.46847558021545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "  pass\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256,input_shape=(260,),activation='relu', kernel_initializer='he_normal'))\n",
        "  model.add(Dense(128,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(3,activation='softmax'))\n",
        "  model.compile(Adam(lr=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "9NZl05YxV7nr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model and predicting\n",
        "start = time.time()\n",
        "batch_size = 12\n",
        "print (\"Using batchsize = {} \".format (batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjwUW-TaV_s5",
        "outputId": "dcf3a67d-f5c3-42e2-f2e6-bc8bee9292a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batchsize = 12 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=150,batch_size=batch_size)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "print(\"Average Acc: %.2f%% and StDev: (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
        "end = time.time()\n",
        "print(\"Training Time\", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUe0osAgWDQC",
        "outputId": "d140bae3-9abb-4862-e612-86bcfe78fba4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.8841 - accuracy: 0.6366\n",
            "Epoch 2/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8458\n",
            "Epoch 3/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9169\n",
            "Epoch 4/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9620\n",
            "Epoch 5/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9810\n",
            "Epoch 6/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9810\n",
            "Epoch 7/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0809 - accuracy: 0.9760\n",
            "Epoch 8/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9750\n",
            "Epoch 9/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9760\n",
            "Epoch 10/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9820\n",
            "Epoch 11/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9780\n",
            "Epoch 12/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9780\n",
            "Epoch 13/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9800\n",
            "Epoch 14/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9800\n",
            "Epoch 15/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9810\n",
            "Epoch 16/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9750\n",
            "Epoch 17/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9800\n",
            "Epoch 18/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9790\n",
            "Epoch 19/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9800\n",
            "Epoch 20/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9820\n",
            "Epoch 21/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9790\n",
            "Epoch 22/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9780\n",
            "Epoch 23/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9840\n",
            "Epoch 24/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9269\n",
            "Epoch 25/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8569\n",
            "Epoch 26/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9540\n",
            "Epoch 27/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9760\n",
            "Epoch 28/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9820\n",
            "Epoch 29/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9800\n",
            "Epoch 30/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9800\n",
            "Epoch 31/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9800\n",
            "Epoch 32/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9810\n",
            "Epoch 33/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9810\n",
            "Epoch 34/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9800\n",
            "Epoch 35/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9820\n",
            "Epoch 36/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9840\n",
            "Epoch 37/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.9790\n",
            "Epoch 38/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9780\n",
            "Epoch 39/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9780\n",
            "Epoch 40/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9790\n",
            "Epoch 41/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9810\n",
            "Epoch 42/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9790\n",
            "Epoch 43/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9820\n",
            "Epoch 44/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9800\n",
            "Epoch 45/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9840\n",
            "Epoch 46/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9790\n",
            "Epoch 47/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9800\n",
            "Epoch 48/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9850\n",
            "Epoch 49/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9790\n",
            "Epoch 50/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9790\n",
            "Epoch 51/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9790\n",
            "Epoch 52/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9820\n",
            "Epoch 53/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9800\n",
            "Epoch 54/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9770\n",
            "Epoch 55/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8999\n",
            "Epoch 56/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.8969\n",
            "Epoch 57/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9530\n",
            "Epoch 58/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9790\n",
            "Epoch 59/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 0.9800\n",
            "Epoch 60/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9830\n",
            "Epoch 61/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9860\n",
            "Epoch 62/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9790\n",
            "Epoch 63/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9800\n",
            "Epoch 64/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9830\n",
            "Epoch 65/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9830\n",
            "Epoch 66/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9810\n",
            "Epoch 67/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9850\n",
            "Epoch 68/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9820\n",
            "Epoch 69/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9800\n",
            "Epoch 70/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9840\n",
            "Epoch 71/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9870\n",
            "Epoch 72/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9830\n",
            "Epoch 73/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9830\n",
            "Epoch 74/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9790\n",
            "Epoch 75/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9840\n",
            "Epoch 76/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9810\n",
            "Epoch 77/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9840\n",
            "Epoch 78/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9810\n",
            "Epoch 79/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9860\n",
            "Epoch 80/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9810\n",
            "Epoch 81/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9830\n",
            "Epoch 82/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9870\n",
            "Epoch 83/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0239 - accuracy: 0.9830\n",
            "Epoch 84/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9810\n",
            "Epoch 85/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.1000 - accuracy: 0.9550\n",
            "Epoch 86/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9329\n",
            "Epoch 87/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9560\n",
            "Epoch 88/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9790\n",
            "Epoch 89/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9820\n",
            "Epoch 90/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9860\n",
            "Epoch 91/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9820\n",
            "Epoch 92/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9830\n",
            "Epoch 93/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9830\n",
            "Epoch 94/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9840\n",
            "Epoch 95/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9860\n",
            "Epoch 96/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9800\n",
            "Epoch 97/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9820\n",
            "Epoch 98/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9860\n",
            "Epoch 99/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 0.9830\n",
            "Epoch 100/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9860\n",
            "Epoch 101/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9850\n",
            "Epoch 102/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9860\n",
            "Epoch 103/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9850\n",
            "Epoch 104/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9860\n",
            "Epoch 105/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9820\n",
            "Epoch 106/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9840\n",
            "Epoch 107/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9860\n",
            "Epoch 108/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9860\n",
            "Epoch 109/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9850\n",
            "Epoch 110/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9800\n",
            "Epoch 111/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9820\n",
            "Epoch 112/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9840\n",
            "Epoch 113/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9830\n",
            "Epoch 114/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9850\n",
            "Epoch 115/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9860\n",
            "Epoch 116/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9860\n",
            "Epoch 117/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9840\n",
            "Epoch 118/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9830\n",
            "Epoch 119/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9860\n",
            "Epoch 120/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9820\n",
            "Epoch 121/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9820\n",
            "Epoch 122/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9810\n",
            "Epoch 123/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9820\n",
            "Epoch 124/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9840\n",
            "Epoch 125/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9830\n",
            "Epoch 126/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9820\n",
            "Epoch 127/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9870\n",
            "Epoch 128/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9740\n",
            "Epoch 129/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9299\n",
            "Epoch 130/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.9530\n",
            "Epoch 131/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9760\n",
            "Epoch 132/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9790\n",
            "Epoch 133/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9860\n",
            "Epoch 134/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9830\n",
            "Epoch 135/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9830\n",
            "Epoch 136/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9860\n",
            "Epoch 137/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9840\n",
            "Epoch 138/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9820\n",
            "Epoch 139/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9850\n",
            "Epoch 140/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9850\n",
            "Epoch 141/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9820\n",
            "Epoch 142/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9830\n",
            "Epoch 143/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9860\n",
            "Epoch 144/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 0.9840\n",
            "Epoch 145/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9800\n",
            "Epoch 146/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9850\n",
            "Epoch 147/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9860\n",
            "Epoch 148/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9820\n",
            "Epoch 149/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9860\n",
            "Epoch 150/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9810\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "84/84 [==============================] - 2s 4ms/step - loss: 0.8915 - accuracy: 0.6396\n",
            "Epoch 2/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8308\n",
            "Epoch 3/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.9119\n",
            "Epoch 4/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9429\n",
            "Epoch 5/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9740\n",
            "Epoch 6/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9690\n",
            "Epoch 7/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9830\n",
            "Epoch 8/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9820\n",
            "Epoch 9/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9860\n",
            "Epoch 10/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9830\n",
            "Epoch 11/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9770\n",
            "Epoch 12/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9750\n",
            "Epoch 13/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9790\n",
            "Epoch 14/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9630\n",
            "Epoch 15/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9510\n",
            "Epoch 16/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9760\n",
            "Epoch 17/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9820\n",
            "Epoch 18/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9860\n",
            "Epoch 19/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9850\n",
            "Epoch 20/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9860\n",
            "Epoch 21/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.9890\n",
            "Epoch 22/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9860\n",
            "Epoch 23/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9860\n",
            "Epoch 24/150\n",
            "84/84 [==============================] - 1s 7ms/step - loss: 0.0192 - accuracy: 0.9850\n",
            "Epoch 25/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9880\n",
            "Epoch 26/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9850\n",
            "Epoch 27/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9850\n",
            "Epoch 28/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9850\n",
            "Epoch 29/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9860\n",
            "Epoch 30/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9870\n",
            "Epoch 31/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 0.9890\n",
            "Epoch 32/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9870\n",
            "Epoch 33/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9880\n",
            "Epoch 34/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9870\n",
            "Epoch 35/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9870\n",
            "Epoch 36/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9880\n",
            "Epoch 37/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9900\n",
            "Epoch 38/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9870\n",
            "Epoch 39/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9870\n",
            "Epoch 40/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9610\n",
            "Epoch 41/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8969\n",
            "Epoch 42/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9349\n",
            "Epoch 43/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9730\n",
            "Epoch 44/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9840\n",
            "Epoch 45/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9860\n",
            "Epoch 46/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9860\n",
            "Epoch 47/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9880\n",
            "Epoch 48/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9870\n",
            "Epoch 49/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 50/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 51/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9840\n",
            "Epoch 52/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9820\n",
            "Epoch 53/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9840\n",
            "Epoch 54/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9860\n",
            "Epoch 55/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9850\n",
            "Epoch 56/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9840\n",
            "Epoch 57/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9850\n",
            "Epoch 58/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 59/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9820\n",
            "Epoch 60/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 61/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9860\n",
            "Epoch 62/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9840\n",
            "Epoch 63/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9850\n",
            "Epoch 64/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9840\n",
            "Epoch 65/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9890\n",
            "Epoch 66/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9850\n",
            "Epoch 67/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9850\n",
            "Epoch 68/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9890\n",
            "Epoch 69/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9860\n",
            "Epoch 70/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9860\n",
            "Epoch 71/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9850\n",
            "Epoch 72/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 73/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9890\n",
            "Epoch 74/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 75/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9820\n",
            "Epoch 76/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 77/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9850\n",
            "Epoch 78/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 79/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9900\n",
            "Epoch 80/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9900\n",
            "Epoch 81/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 82/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.9409\n",
            "Epoch 83/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9319\n",
            "Epoch 84/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9770\n",
            "Epoch 85/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9860\n",
            "Epoch 86/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9870\n",
            "Epoch 87/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9850\n",
            "Epoch 88/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 0.9870\n",
            "Epoch 89/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 90/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9870\n",
            "Epoch 91/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9860\n",
            "Epoch 92/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9880\n",
            "Epoch 93/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9850\n",
            "Epoch 94/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9850\n",
            "Epoch 95/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 96/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9850\n",
            "Epoch 97/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 98/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9890\n",
            "Epoch 99/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 100/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 101/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 102/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9900\n",
            "Epoch 103/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 104/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9860\n",
            "Epoch 105/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9850\n",
            "Epoch 106/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 107/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 108/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9870\n",
            "Epoch 109/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9860\n",
            "Epoch 110/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9900\n",
            "Epoch 111/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 112/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9890\n",
            "Epoch 113/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9860\n",
            "Epoch 114/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9900\n",
            "Epoch 115/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 116/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9850\n",
            "Epoch 117/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9840\n",
            "Epoch 118/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9830\n",
            "Epoch 119/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 120/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 121/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9900\n",
            "Epoch 122/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9850\n",
            "Epoch 123/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9900\n",
            "Epoch 124/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9850\n",
            "Epoch 125/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9870\n",
            "Epoch 126/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9870\n",
            "Epoch 127/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 128/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 129/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 130/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 131/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9900\n",
            "Epoch 132/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 133/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 134/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 135/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9860\n",
            "Epoch 136/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9890\n",
            "Epoch 137/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 138/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9900\n",
            "Epoch 139/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 140/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9880\n",
            "Epoch 141/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 142/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 143/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9890\n",
            "Epoch 144/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9399\n",
            "Epoch 145/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.9039\n",
            "Epoch 146/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9750\n",
            "Epoch 147/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 0.9900\n",
            "Epoch 148/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9840\n",
            "Epoch 149/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9880\n",
            "Epoch 150/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9890\n",
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 256)               66816     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108163 (422.51 KB)\n",
            "Trainable params: 108163 (422.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "84/84 [==============================] - 1s 3ms/step - loss: 0.8393 - accuracy: 0.6480\n",
            "Epoch 2/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8400\n",
            "Epoch 3/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.9170\n",
            "Epoch 4/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.1281 - accuracy: 0.9650\n",
            "Epoch 5/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9790\n",
            "Epoch 6/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0734 - accuracy: 0.9800\n",
            "Epoch 7/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9880\n",
            "Epoch 8/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9860\n",
            "Epoch 9/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9840\n",
            "Epoch 10/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9870\n",
            "Epoch 11/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0351 - accuracy: 0.9870\n",
            "Epoch 12/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9870\n",
            "Epoch 13/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9870\n",
            "Epoch 14/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9840\n",
            "Epoch 15/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9880\n",
            "Epoch 16/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9850\n",
            "Epoch 17/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 0.9840\n",
            "Epoch 18/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9860\n",
            "Epoch 19/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9850\n",
            "Epoch 20/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9850\n",
            "Epoch 21/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9860\n",
            "Epoch 22/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9870\n",
            "Epoch 23/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9870\n",
            "Epoch 24/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9880\n",
            "Epoch 25/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9870\n",
            "Epoch 26/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9860\n",
            "Epoch 27/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9870\n",
            "Epoch 28/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9880\n",
            "Epoch 29/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 0.9870\n",
            "Epoch 30/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9870\n",
            "Epoch 31/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9850\n",
            "Epoch 32/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.8290\n",
            "Epoch 33/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9080\n",
            "Epoch 34/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9710\n",
            "Epoch 35/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9770\n",
            "Epoch 36/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9870\n",
            "Epoch 37/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9870\n",
            "Epoch 38/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9860\n",
            "Epoch 39/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9880\n",
            "Epoch 40/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9820\n",
            "Epoch 41/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9860\n",
            "Epoch 42/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9880\n",
            "Epoch 43/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9880\n",
            "Epoch 44/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9850\n",
            "Epoch 45/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9880\n",
            "Epoch 46/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9850\n",
            "Epoch 47/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9840\n",
            "Epoch 48/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9870\n",
            "Epoch 49/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9840\n",
            "Epoch 50/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9850\n",
            "Epoch 51/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9840\n",
            "Epoch 52/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9890\n",
            "Epoch 53/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9880\n",
            "Epoch 54/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9880\n",
            "Epoch 55/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9890\n",
            "Epoch 56/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9870\n",
            "Epoch 57/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9880\n",
            "Epoch 58/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9830\n",
            "Epoch 59/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9870\n",
            "Epoch 60/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9850\n",
            "Epoch 61/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9850\n",
            "Epoch 62/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9890\n",
            "Epoch 63/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9900\n",
            "Epoch 64/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9860\n",
            "Epoch 65/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9900\n",
            "Epoch 66/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9860\n",
            "Epoch 67/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9900\n",
            "Epoch 68/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 69/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9870\n",
            "Epoch 70/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9900\n",
            "Epoch 71/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9890\n",
            "Epoch 72/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 0.9880\n",
            "Epoch 73/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9870\n",
            "Epoch 74/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9890\n",
            "Epoch 75/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9860\n",
            "Epoch 76/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9870\n",
            "Epoch 77/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 78/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 79/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 80/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 81/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9880\n",
            "Epoch 82/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 83/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 84/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9860\n",
            "Epoch 85/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 86/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9880\n",
            "Epoch 87/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9590\n",
            "Epoch 88/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8890\n",
            "Epoch 89/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9620\n",
            "Epoch 90/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9790\n",
            "Epoch 91/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9920\n",
            "Epoch 92/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9870\n",
            "Epoch 93/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9890\n",
            "Epoch 94/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9890\n",
            "Epoch 95/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9890\n",
            "Epoch 96/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9880\n",
            "Epoch 97/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9890\n",
            "Epoch 98/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 99/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9890\n",
            "Epoch 100/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 101/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9870\n",
            "Epoch 102/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9860\n",
            "Epoch 103/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9850\n",
            "Epoch 104/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9900\n",
            "Epoch 105/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 106/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9880\n",
            "Epoch 107/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9880\n",
            "Epoch 108/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9900\n",
            "Epoch 109/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9900\n",
            "Epoch 110/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9860\n",
            "Epoch 111/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 112/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9870\n",
            "Epoch 113/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 114/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9870\n",
            "Epoch 115/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 116/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9840\n",
            "Epoch 117/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9900\n",
            "Epoch 118/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 119/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9870\n",
            "Epoch 120/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 121/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9900\n",
            "Epoch 122/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 123/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 124/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9860\n",
            "Epoch 125/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9870\n",
            "Epoch 126/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9900\n",
            "Epoch 127/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9870\n",
            "Epoch 128/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9890\n",
            "Epoch 129/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9860\n",
            "Epoch 130/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 131/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9880\n",
            "Epoch 132/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 133/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9860\n",
            "Epoch 134/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 135/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9880\n",
            "Epoch 136/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9880\n",
            "Epoch 137/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 138/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 139/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9880\n",
            "Epoch 140/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9870\n",
            "Epoch 141/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9900\n",
            "Epoch 142/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9890\n",
            "Epoch 143/150\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9870\n",
            "Epoch 144/150\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9900\n",
            "Epoch 145/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.2535 - accuracy: 0.9400\n",
            "Epoch 146/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.1440 - accuracy: 0.9460\n",
            "Epoch 147/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9810\n",
            "Epoch 148/150\n",
            "84/84 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9850\n",
            "Epoch 149/150\n",
            "84/84 [==============================] - 0s 6ms/step - loss: 0.0165 - accuracy: 0.9860\n",
            "Epoch 150/150\n",
            "84/84 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9860\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "Average Acc: 76.38% and StDev: (1.58%)\n",
            "Training Time 256.9503183364868\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vhM7Yf_mUAr6BhB4BO8WG7pfy9Xy8BmW",
      "authorship_tag": "ABX9TyOy5F14AGba+yk7qr2FsvGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}